#### 背景介绍

&emsp;上一篇文章中介绍了如何使用Prometheus监控接口的QPS, 这里我们介绍一下监控接口的响应时间, 那么如何监控接口的响应时间, 这要从Prometheus支持的数据类型说起. 这里还是用部署服务来作为说明.

#### HISTOGRAMS AND SUMMARIES

我们知道Prometheus支持4中数据类型, 前面简单的两种`Counter`和`Gauge`暂时先不说了, 今天主要说一下另外2个数据类型`HISTOGRAM`和`SUMMARY`.

这两个数据类型非常相似, 都非常适合用于统计持续一定时间的统计, 比如最常用的就是`接口响应时间`,使用这2种数据类型, 方法也很简单, 核心代码如下:

```python
REQUEST_HISTOGRAM = Histogram('response_latency_seconds', 'Response latency (seconds)', ["interface"])
DEPLOY_REQUEST_HISTOGRAM = REQUEST_HISTOGRAM.labels(interface="/deploy")
ROLLBACK_REQUEST_HISTOGRAM = REQUEST_HISTOGRAM.labels(interface="/rollback")

@app.route("/deploy", methods=["POST"])
@DEPLOY_REQUEST_HISTOGRAM.time()
def deploy():
    if request.method == "POST":
        data = request.get_json()
        return "OK"
        
@app.route("/rollback", methods=["POST"])
@ROLLBACK_REQUEST_HISTOGRAM.time()
def rollback():
    if request.method == "POST":
        return "OK"
```

`Summary`使用方法也一样, 只需要改一个方法名称即可. 拿上面的代码举例子, 他们的相同点是都可以返回`response_latency_seconds_count`和`response_latency_seconds_sum`这两个数据, 这两个数据的类型都是`Counter`, 前面的表示接口总得请求个数, 类似于上一篇文章讲的单独定一个`Counter`, 每一个请求加一, 其实没有必要, 使用`HISTOGRAM和SUMMARY`默认都会有接口的统计个数的, 另一个是这些请求的响应时间的总和:

![image](https://user-images.githubusercontent.com/7486508/41818500-edbbe9c8-77e2-11e8-8d51-6a47c05109d0.png)

如果要从这些数据中计算出接口的1分钟内的平均响应时间的话, 我们可以使用如下的公式:

```
rate(http_request_duration_seconds_sum[1m]) / rate(http_request_duration_seconds_count[1m])
```

下面使用另一个服务的图表来说明上面的公式, 如下图某个服务的接口响应时间, 上面的公式可以反应接口响应时间, 但是这个公式的结果默认是按照每个label分开显示的, 如下图, 可以看到图下面有很多选项, 看起来很乱.

![image](https://user-images.githubusercontent.com/7486508/41818573-4d822b3c-77e4-11e8-89bb-dadaf6d10bf7.png)

这时候可以结合`sum() by`的语法来更加友好地显示我们想看的图, 只有`sum`的时候, 会把`HISTOGRAM和SUMMARY`打出来的数据全部加在一起了, 这时候可以使用`by`来各种分组显示.

![image](https://user-images.githubusercontent.com/7486508/41819252-c3338dde-77ef-11e8-900a-4622656cb10f.png)
![image](https://user-images.githubusercontent.com/7486508/41819678-1dc21dd6-77f7-11e8-8e09-5f50d47c7ded.png)

根据不同的主机来查看.
![image](https://user-images.githubusercontent.com/7486508/41819791-4989f77a-77f9-11e8-89ad-163e9156ea32.png)

`HISTOGRAM和SUMMARY`相同点:

```
如果想要统计接口的响应时间, 使用任何一种数据类型, 都一样.
```

下面说说不同点, 谈起不同点, 还需要说起分位数这个需求, 比如说我们想要看服务接口95%的响应时间都小于多少秒, `Summary`数据类型会直接在客户端计算好性能分布的分位数, 而`Histogram`会提供很多预先配置好的bucket, 如下:
![image](https://user-images.githubusercontent.com/7486508/41820441-821fdacc-7804-11e8-9f4a-9965662a9ea1.png)

图中的`le`表示`less than`的意思, 小于等于的意思, `le`后面的值是多少秒的意思, 后面的值是统计的个数的意思, 比如响应延时小于等于1秒的个数为8个.按照上图的含义是所有的请求响应时间都位于`0.75-1秒`之间.

```
Summary = Histogram + histogram_quantile()
```

`Summary`的percentile的计算都是在于客户端上, 而`Histogram`的计算是在server端来计算的, 所以出于最小化的影响业务, 建议使用`Histogram`来计算`percentile`.

![image](https://user-images.githubusercontent.com/7486508/41820636-98b1ba6e-7807-11e8-85d6-bfc8896c17df.png)

`istogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket[1m])) by (le, api))`


#### 参考链接

* https://prometheus.io/docs/practices/histograms/
* https://prometheus.io/docs/prometheus/latest/querying/functions/#histogram_quantile
* https://povilasv.me/prometheus-tracking-request-duration/
* https://github.com/prometheus/client_python




