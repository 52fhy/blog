#### 背景介绍

&emsp;公司的RabbitMQ服务器都是我在维护, 有一次, 突然收到线上MQ的机器的出口流量变高的报警.之前的带宽一般都是1M左右, 这次突然涨到了30M, 增加了30倍的流量, 由于服务器的出口带宽上限一般是G级别的, 所以当时除了流量增加外, 服务暂未受影响, 只是这个情况是不正常, 收到报警后有时间慢慢分析.


#### 分析过程

* 查看RabbitMQ的SLB带宽情况

收到报警的是单台机器的流量的报警, 单台报警后我先马上看了集群中其它另外几台的流量, 发现都是变高了, 为了确定是服务跟MQ的流量高了而不仅仅是MQ内部的流量高, 我马上看看了MQ的SLB的带宽情况.

![image](https://user-images.githubusercontent.com/7486508/44001108-3021a3f6-9e5e-11e8-922e-20ed310bef60.png)


* 使用`iftop`查看具体的IP

看到流量突然增加, 第一时间想到的就是查看哪个服务的问题, 我是用`iftop`查看了具体哪个IP跟MQ之间的流量变高了.然后根据IP查到了业务, 然后把这个结果告诉了业务, 业务最后根据日志排查了出来.


#### 分析结果

由于数据发送方手工刷了一批次的数据, 由于手工刷的数据不是按照业务双方约定好的数据格式发送的, 导致消费方的服务解析数据的时候抛了异常, 结果消费方没有对这个异常进行处理, 导致这个消息一直处理失败, 而且消费方设置了手工ack模式, 异常的消息肯定没有ack, 没有ack的消息是不会从RabbitMQ上删除的, 导致RabbitMQ不断发送数据到消费方, 造成了死循环. 这一点从流量图中也可以看到, 流出的流量突增.

#### 现场模拟

````python
import pika

def on_message(channel, method_frame, header_frame, body):
    print("*" * 20)
    print(method_frame.delivery_tag)
    print(body)
    print("-" * 20)


credentials = pika.PlainCredentials('root', '123456')
parameters = pika.ConnectionParameters('192.168.1.1', 5672, '/', credentials)
connection = pika.BlockingConnection(parameters)
channel = connection.channel()
channel.basic_consume(on_message, queue="test", no_ack=False)
try:
    channel.start_consuming()
except KeyboardInterrupt:
    channel.stop_consuming()
    connection.close()
````

如上面的代码, channel的模式我设置成为手工ack的模式, 但是我收到消息后不去ack, 这时候这个消息会一直给客户端发送, 不会从server上删除, 直到server收到ack后才会删除.