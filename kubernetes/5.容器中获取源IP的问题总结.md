#### 背景介绍

在迁移服务到容器中的过程中遇到这样一个问题, 之前服务都是部署在ECS服务器上, ECS的IP一般是不会变化的, 所以业务上经常会让运维查看某一个IP具体属于哪一个服务, 来确定是哪个服务调用了自己的接口, 其实做好的方法是在业务的接口中让调用方传一些参数来确定调用方是谁, IP是不可靠的. 但是内网中用IP来判断调用方的还是存在的.服务迁移到容器后, 业务发现服务的调用方IP都成了k8s其中任意一个Node的IP,  代码也没有任何改动,使用的是Java的request.getremouteAddr(), 开始我以为是业务的代码的问题, 后来看了下, 没有发现什么异常, 就是很简单的获取远程的IP, 没有其他的特殊的逻辑, 后来我自己写了一个简单的Java服务, 发现确实存在这样的问题, 这应该不是个例.

#### 解决过程

后来我自己实在想不通, 以为是阿里云在网络上做了什么手脚, 阿里云做的NAT转换, 后来问了阿里云的工程师, 他们说没有, 并且给出了一些可以查询的建议, 让我查看`service.spec.externalTrafficPolicy`参数的设置.后来我仔细查了一下这个参数的含义.大概理解了一下.

当一个k8s的service采用 `Type=NodePort`或者`Type=LoadBalancer`的时候(这两种其实是一样的, 只不过后者挂了一个负载均衡指向了node节点),  `externalTrafficPolicy`这个配置项有2个可选:

1. 默认为`Cluster`:
 
  * kube-proxy在所有的Node节点上启动NodePort
  * 一般服务的pod会少于node的节点数量, 当请求到的node节点上没有启动pod的时候, 这时候Kube-proxy会使用NAT的技术, 把请求转发到有pod的node上, 这时候就会出现容器中的服务查询到的请求的来源IP是一个node节点的IP, 而且该节点上没有部署这个服务;如果请求的node节点上正好有该服务的pod, 这时候就不会发生转发了;
  * 如果Type=LoadBalancer, 那么SLB会把所有的node节点挂载到这个SLB上, 因为请求到那个节点都一样的. 对于整个集群来说, 这也利于请求的均衡性;

2. 当配置为`Local`时:

  * kube-proxy在所有的Node节点上启动NodePort
  * kube-proxy只会将请求转发到本节点的pod上, 所以pod中的服务可以获取到真实的请求IP
  * 如果请求一下没有pod的node的时候, 服务是不可用的, 端口只是在node上监听着而已. 所以LoadBalencer模式下, 你会发现SLB后面只存在启动着pod的node节点
  * 这时候会存在node间流量不均衡的现象, 需要根据实际场景进行取舍.


#### 参考链接

* https://kubernetes.io/docs/tutorials/services/source-ip/