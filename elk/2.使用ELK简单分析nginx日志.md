#### 背景介绍

&emsp;上一篇文章简单介绍了我在一下科技的时候采用的日志处理方案, 这种方案更多的是用于开发者调试错误日志, 和一些简单的分析的工作, 大数据部分和我们这边的日志采集使用的是同一套, 都是从filebeat采集, 只是入库到不同的kafka而已. 今天我就用nginx日志来梳理一下ELK的简单使用方式.


#### 日志格式

&emsp;日志采集入库之前一定会面对的就是日志格式的问题, 因为日志格式如果配置的很奇怪的话, 后面数据分析的同事就会很蛋疼, 这个蛋疼的问题我自己就遇到了, 使用Logstash的正则规则去解析nginx的日志, 这里总结一下重要的点, 以nginx为例子, nginx的日志格式是很规范的, 唯一需要注意的是使用什么分隔符的问题, 一般来说, 使用`-`或者`|`都是不错的选择, 但是使用这个偶尔会出现一个问题, 如果用户访问的url中带有相同的字符的时候就会不利于日志的解析, 解析可能会报错, 这时候可以选择一个不可见字符来作为日志的分隔符, 我们使用的是`^A`这个字符, 这个字符在终端中输入的方式为`Ctrl+V+A`, 这个字符在Logstash中解析的时候为分隔符`\u0001`.

生产环境nginx日志格式配置(注意不能直接复制这个粘贴到你的nginx配置文件中, 必须手工敲出来):

```
log_format  main '$http_host^A$remote_addr^A$time_local^A$request_time^A$request^A$status^A$body_bytes_sent^A$http_referer^A$http_user_agent^A$request_body';
```


nginx常用字段含义:

*参数* | *说明* | *示例* 
---- | --- | ---
| $http_host | 用户请求的主机名 | www.bbobo.com |
| $remote_addr | 用户的IP地址 | 124.64.25.16 |
| $http_x_forwarded_for | 用户的IP地址(当nginx前面挂了代理的时候) | 124.64.25.16 |
| $time_local | 日志打印的时间 | 09/Feb/2018:16:11:03 +0800 |
| $request_time | 服务端的处理耗时(从nginx接收到第一个byte开始计算) | 0.01 |
| $request | 用户请求的方法以及路径参数等 | GET /cc/checkcookie?type=cookie&ctime=0.2123393398508353 HTTP/1.1 | 
| $status | HTTP状态码 | 200 |
| $body_bytes_sent | 返回给用户的HTTP body大小(byte) | 2954 |
| $http_referer | 源跳转地址(从哪儿跳转过来的) | http://www.baidu.com |
| $http_user_agent | 用户的UA | curl/7.54.0 |

logstash从kafka中获取到nginx日之后会去解析每一个上面的字段, 核心配置如下:

```ruby
filter {
       grok {
		match => { "message" => "%{IPORHOST:http_host}\u0001%{IP:client_ip}\u0001%{HTTPDATE:timestamp}\u0001%{NUMBER:request_ti
me}\u0001%{WORD:verb} %{URIPATHPARAM:request} HTTP/%{NUMBER:httpversion}\u0001%{NUMBER:status}\u0001%{NUMBER:body_length}\u0001%{DATA:r
eferer}\u0001%{DATA:ua}\u0001%{DATA:request_body}"}
       }
}
```

#### 日志采集

&emsp;数据分析的第一步肯定是要获取日志, 之前一般采用的架构是采用每一台应用服务器上部署一个Logstash来采集日志, 后来由于Logstash太占用资源, 官方又使用go语言开发了一个更加轻量专一的日志采集工具--`filebeat`, 为了方便管理, 我们统一采用supervisor来监控filebeat的运行, supervisor采用系统安装的方法(yum或者apt-get), filebeat会放置在`/usr/local/filebeat`目录下, 下面是supervisor的配置文件:

```python
filebeat.ini

[program:filebeat]
command=/usr/local/filebeat/filebeat -e -c /usr/local/filebeat/conf/filebeat.yml
autostart=true
autorestart=true
redirect_stderr = true
stdout_logfile=/var/log/filebeat_nginx_stdout.log
stdout_logfile_maxbytes=50MB
stdout_logfile_backups=3
stderr_logfile=/var/log/filebeat_nginx_stderr.log
stderr_logfile_maxbytes=50MB
stderr_logfile_backups=3
```

filebeat(6.2)配置文件如下:

```yaml
filebeat.yml
#=========================== Filebeat prospectors =============================

filebeat.prospectors:

- type: log

  # Change to true to enable this prospector configuration.
  enabled: true

  # Paths that should be crawled and fetched. Glob based paths.
  paths:
    - /home/git/logs/access_log
    #- c:\programdata\elasticsearch\logs\*

#==================== Elasticsearch template setting ==========================

setup.template.settings:
  index.number_of_shards: 3
  #index.codec: best_compression
  #_source.enabled: false

#================================ Out =====================================
output.kafka:
  hosts: ["192.168.112.211:19092","192.168.112.212:19092","192.168.112.213:19092"]
  topic: "mp_service_www_bbobo_com"
  required_acks: 1
  compression: gzip
  max_message_bytes: 1000000
```

根据上面的配置后, filebeat就会向我们搭建的kafka集群中上传日志了, 到此filebeat部分配置完毕.


#### kafka








#### 参考链接

* [filebeat官方文档](https://www.elastic.co/guide/en/beats/filebeat/current/index.html)