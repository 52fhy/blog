#### 背景介绍

&emsp;前面介绍了钱方数据库方案的更改以及新版集群的搭建,这里说说数据从老的数据库迁移到新的数据库集群的一些要点.首先要明白,数据库迁移也好,服务更改也好,核心是在数据安全稳定的基础上保证最少的宕机时间,由于数据库的迁移是一点一点来的,先把一些不是很核心的服务的数据迁移过来做一些前期的测试,所以这里选择使用逻辑的方式备份恢复,使用mysqldump.这里有这么几种情况:

* 数据只读不写,这时候直接迁移即可,不用考虑停服务,迁移完后直接修改服务的数据库地址
* 该服务所使用的数据库有部分不变,有部分变化,这时候可以先把不变的数据迁移过来,变化的数据先导出恢复一部分,然后等晚上停服务把剩下的数据再迁移过来,这样会省下不少时间,这是本文的重点
* 所有数据都是有写入操作的,方法如上,先在业务量少的时候迁移一部分,然后再在晚上停服务迁移省下的部分数据


这里以`test`数据库的`student`表来举例,这个表会一直不断写入数据,而且量很大

student表结构:

```sql
MySQL [test]> show create table student;
+---------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Table   | Create Table                                                                                                                                                                                                        |
+---------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| student | CREATE TABLE `student` (
  `id` int(4) NOT NULL AUTO_INCREMENT,
  `name` varchar(64) NOT NULL DEFAULT '',
  `age` int(4) DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=152 DEFAULT CHARSET=utf8 |
+---------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

```


模拟程序不断写入数据:

```python
#!/usr/bin/env python
# coding:utf-8
import os
import sys
import time
from qfcommon.base.dbpool import install, with_database, get_connection

DATABASE = {
    'sight': {
        'engine':'pymysql',
        'db': 'test',
        'host': '127.0.0.1',
        'port': 3306,
        'user': 'root',
        'passwd': '',
        'charset': 'utf8',
        'conn': 16,
    }
}

install(DATABASE)

for i in range(10000):
    with get_connection("sight") as conn:
        conn.query("insert into student (name, age) values('rocky', 27)")
        count = conn.query("select count(1) from test.student")
        print count
    time.sleep(0.1)

```


#### 迁移步骤

* 先在新的数据库上创建一个`test`数据库

```sql
>create database test;

```

* 使用`mysqldump`命令正常备份数据

```sql
>mysqldump -h127.1 -uroot -q --default-character-set=utf8 --single-transaction test student > student.sql

# 注意mysqldump默认会对当前操作的数据库加读锁,操作完成后释放锁,读锁的意思是只允许读.
```

* 使用scp命令拷贝到新数据库服务器上
* 恢复数据

```sql
$mysql -h127.1 -uqfpay -pqfpay test < student.sql

```

* 因为该表的`id`为自增的,所以需要看看最后的id是多少

```sql
MariaDB [test]> select * from student order by id desc limit 10;
+-----+-------+------+
| id  | name  | age  |
+-----+-------+------+
| 119 | rocky |   27 |
| 118 | rocky |   27 |
| 117 | rocky |   27 |
| 116 | rocky |   27 |
| 115 | rocky |   27 |
| 114 | rocky |   27 |
| 113 | rocky |   27 |
| 112 | rocky |   27 |
| 111 | rocky |   27 |
| 110 | rocky |   27 |
+-----+-------+------+
10 rows in set (0.01 sec)
```

* 把剩下的数据迁移过来,这里需要停止使用该库的所有服务,保证没有数据写入,一般选择晚上,这种方法比起mysqldump速度更快


```sql
MySQL [test]> select * from student where id>119 into outfile "/home/qfpay/tmp/student.csv";
Query OK, 78 rows affected (0.00 sec)

这里注意导出的文件路径要让mysql的运行用户有权限,而且文件之前不存在,该命令会把剩下的数据导出来,格式为以空格分隔,每行一条记录,顺序排列,也可以自定义格式,这里使用默认即可

```

* 先把`student.csv`拷贝到新数据库的服务器上,然后把剩下的数据恢复追加到之前恢复的`student`表后面

```sql
MariaDB [test]> LOAD DATA INFILE '/home/qfpay/tmp/student.csv' INTO TABLE student;
Query OK, 78 rows affected (0.01 sec)
Records: 78  Deleted: 0  Skipped: 0  Warnings: 0

```

* 检查数据是否已经全部恢复

```sql
MariaDB [test]> select * from student order by id desc limit 10;
+-----+-------+------+
| id  | name  | age  |
+-----+-------+------+
| 197 | rocky |   27 |
| 196 | rocky |   27 |
| 195 | rocky |   27 |
| 194 | rocky |   27 |
| 193 | rocky |   27 |
| 192 | rocky |   27 |
| 191 | rocky |   27 |
| 190 | rocky |   27 |
| 189 | rocky |   27 |
| 188 | rocky |   27 |
+-----+-------+------+
10 rows in set (0.00 sec)


```


#### 数据迁移过程中遇到MYISAM表的问题

&emsp;事情是这样的,在迁移数据库的过程中遇到了这样的一种情况,由于mariadb集群只支持Innodb的引擎,由于疏忽,把几个MYISAM的表结构的数据库迁移到了集群上,导致了集群的同步有问题,主库的更新没问题,但是数据都没有更新到从库上,幸亏这几个数据库更新的很少,读的多,最后的解决办法是,先在主库上把这些MYISAM的表结构都修改成Innnodb的表结构:

```
ALTER TABLE table_name ENGINE=InnoDB;
```

然后备份出来这个库:

```
mysqldump -h127.1 -uroot -p123456 --opt dbname xxx > xxx.sql

这里注意opt参数,会执行drop table if exists, 意思是备份后会删除这个表
```

然后再倒回去就行了:

```
mysql -h127.1 -uroot -p123456 dbname < xxx.sql
```
